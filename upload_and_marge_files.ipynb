{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict, Counter\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [\n",
    "    pd.read_csv(\"../../csvs/all_weeks\\hebrew_2021-07-28_16_33_hebrew16_shani_w2_acdoors_pt1_m_calr.csv\", parse_dates=['Date_Time_1']),\n",
    "    pd.read_csv(\"../../csvs/all_weeks\\hebrew_2021-08-01_13_49_hebrew16_shani_w1_pt2b_m_calr.csv\", parse_dates=['Date_Time_1']),\n",
    "    pd.read_csv(\"../../csvs/all_weeks/hebrew_2021-08-04_11_45_hebrew16_shani_acdoors_w2p1_m_calr.csv\", parse_dates=['Date_Time_1']),\n",
    "    pd.read_csv(\"../../csvs/all_weeks/hebrew_2021-08-10_16_15_hebrew16_shani_w2p2.1_m_calr.csv\", parse_dates=['Date_Time_1']),\n",
    "    pd.read_csv(\"../../csvs/all_weeks/hebrew_2021-08-11_16_24_hebrew16_shani_acdoors_w3_m_calr.csv\", parse_dates=['Date_Time_1']),\n",
    "    pd.read_csv(\"../../csvs/all_weeks/hebrew_2021-08-19_16_17_hebrew16_shani_acdoors_w4_m_calr.csv\", parse_dates=['Date_Time_1']),\n",
    "    pd.read_csv(\"../../csvs/all_weeks/hebrew_2021-08-15_16_24_hebrew16_sahni_acdoors_w3p2_m_calr.csv\", parse_dates=['Date_Time_1']),\n",
    "    pd.read_csv(\"../../csvs/all_weeks/hebrew_2021-08-26_16_12_hebrew16_shani_acdoors_w5_m_calr.csv\", parse_dates=['Date_Time_1']),\n",
    "    pd.read_csv(\"../../csvs/all_weeks/hebrew_2021-08-29_08_41_hebrew16_shani_acdoors_w5_dd_m_calr.csv\", parse_dates=['Date_Time_1']),\n",
    "    pd.read_csv(\"../../csvs/all_weeks/hebrew_2021-09-02_07_54_hebrew16_dark dark week2_m_calr.csv\", parse_dates=['Date_Time_1'])\n",
    "]\n",
    "# dataframes_dd = [\n",
    "#     pd.read_csv(\"../../csvs/week5/hebrew_2021-08-29_08_41_hebrew16_shani_acdoors_w5_dd_m_calr(1).csv\", parse_dates=['Date_Time_1']),\n",
    "#     pd.read_csv(\"../../csvs/week5/hebrew_2021-09-02_07_54_hebrew16_dark dark week2_m_calr(1).csv\", parse_dates=['Date_Time_1']),\n",
    "# ]\n",
    "dict_groups = OrderedDict(Control=[1, 4, 7, 10, 13],\n",
    "                          Group_2=[3, 5, 9, 12, 16],\n",
    "                          Group_3=[2, 6, 8, 11, 14, 15])\n",
    "is_one_file = len(dataframes) == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns_by_metebolic_parm(df, param_name, exclude=False):\n",
    "    if exclude == True:\n",
    "        mask = ~df.columns.str.contains(pat=param_name)\n",
    "        return df.loc[:, mask]\n",
    "    mask = df.columns.str.contains(pat=param_name)\n",
    "    return df.loc[:, mask]\n",
    "\n",
    "def _get_columns_names_list(df):\n",
    "    return df.columns.values.tolist()\n",
    "\n",
    "def _make_dict_to_replace_names(columns_names_list, pattern_addition_to_parms):\n",
    "    leng = len(columns_names_list)\n",
    "    return {columns_names_list[i]: pattern_addition_to_parms + columns_names_list[i] for i in range(leng)}\n",
    "\n",
    "def _get_actuals_values(df):\n",
    "    df_actuals_features_calculeted = df.diff()\n",
    "    first_row_df_cumuletive = df.iloc[0:1]\n",
    "    return df_actuals_features_calculeted.fillna(first_row_df_cumuletive)\n",
    "\n",
    "def incal_get_actuals_from_cumuletive(df, columns_pattern,\n",
    "                                      pattern_addition_to_parms):\n",
    "    # get just the cumuletive columns from the original df\n",
    "    df_cumuletive_culumns = select_columns_by_metebolic_parm(\n",
    "        df, columns_pattern)\n",
    "    # get the columns names of the cumuletive columns\n",
    "    columns_names = _get_columns_names_list(df_cumuletive_culumns)\n",
    "    # dict to replace names\n",
    "    dict_new_names = _make_dict_to_replace_names(columns_names,\n",
    "                                                 pattern_addition_to_parms)\n",
    "    # replace the columns names of the actuals culumns\n",
    "    df_actuals_features = df_cumuletive_culumns.rename(columns=dict_new_names)\n",
    "    df_actuals = _get_actuals_values(df_actuals_features)\n",
    "    return pd.concat([df, df_actuals], axis=1).drop(columns_names, axis=1)\n",
    "\n",
    "def _right_sepert_first_underscore(string):\n",
    "    return tuple(string.rsplit(\"_\", 1))\n",
    "\n",
    "def _assemble_multi_index_axis_1_df(df, d_list, axis_1_names=[\"\", \"\"]):\n",
    "    # make a multi index \n",
    "    mul_i_columns = pd.MultiIndex.from_tuples(d_list, names=axis_1_names)\n",
    "    # assemble new dataframe with multi index columns  \n",
    "    return pd.DataFrame(df.values, index=df.index, columns=mul_i_columns)\n",
    "    # then stack level 1 to the columns (level 1 -> subjects names e.g. 1 2 3...)\n",
    "\n",
    "def incal_wide_to_long_df(wide_df, col_subj_name='subjectID'):\n",
    "    cols_names = _get_columns_names_list(wide_df)\n",
    "    # sepert feature name from cage number and put it in a tuple together ('allmeters', '1')\n",
    "    l_micolumns  = [_right_sepert_first_underscore(col) for col in cols_names]\n",
    "    multi_index_axis_1_df = _assemble_multi_index_axis_1_df(\n",
    "        wide_df, \n",
    "        l_micolumns, \n",
    "        ['', col_subj_name]\n",
    "    )\n",
    "    # https://pandas.pydata.org/docs/user_guide/reshaping.html\n",
    "    return multi_index_axis_1_df.stack(level=1)\n",
    "\n",
    "def flat_list(d_list):\n",
    "    '''\n",
    "    dependencies: itertools\n",
    "    '''\n",
    "    return list(itertools.chain.from_iterable(d_list))\n",
    "\n",
    "def replace_ids_to_group_id(ndarray_ids, groups_names, subjects_within_group):\n",
    "  conditiones = [ndarray_ids.astype('int64') == n for n in subjects_within_group]\n",
    "  choices = groups_names\n",
    "  return np.select(conditiones, choices, ndarray_ids)\n",
    "\n",
    "def incal_create_group_column_from_ids(ids_column, dict_groups):\n",
    "  n_ids_multiple_name = lambda name, n: [name] * len(n)\n",
    "  subjects_vlaues = ids_column.values\n",
    "  items = dict_groups.items()\n",
    "  groups_names = flat_list([n_ids_multiple_name(group, ids) for group, ids in items])\n",
    "  subjects_within_groups = flat_list([ids for ids in dict_groups.values()])\n",
    "  return replace_ids_to_group_id(subjects_vlaues, groups_names, subjects_within_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_parm = \"|\".join(['food', 'water', 'allmeters', 'wheelmeters', 'pedmeters'])\n",
    "pattern_addition_to_parms = 'actual_'\n",
    "\n",
    "df_or_dfs_in_list = dataframes\n",
    "dfs = [incal_get_actuals_from_cumuletive(df, cumulative_parm, pattern_addition_to_parms) for df in df_or_dfs_in_list]\n",
    "dfs_concated = pd.concat(dfs).set_index('Date_Time_1')\n",
    "df = incal_wide_to_long_df(dfs_concated)\n",
    "index_datetime_subjects, df = df.index.to_frame().reset_index(drop=True), df.reset_index(drop=True)\n",
    "\n",
    "groupid = incal_create_group_column_from_ids(index_datetime_subjects['subjectID'], dict_groups)\n",
    "multi_index_df = pd.concat([index_datetime_subjects, pd.Series(groupid, name='Group')], axis=1)\n",
    "df = pd.concat([multi_index_df, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dd_shani_exp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9d0df8d0a6c967036c04416e9cfa4429678e2d11b54414b38f7d0328a69c043"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv_incal_notebooks': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
